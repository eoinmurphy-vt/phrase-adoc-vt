= Docker et Mirantis Kubernetes Engine
:revdate: 25-01-13
:page-revdate: {revdate}
:page-opendocs-origin: /02.deploying/05.docker/05.docker.md
:page-opendocs-slug: /deploying/docker

== Déploiement Kubernetes sur Mirantis Kubernetes Engine

Suivez les instructions dans la xref:kubernetes.adoc[section Kubernetes].

[NOTE]
====
{product-name} ne prend pas en charge les clusters Kubernetes / Swarm mixtes.
====

== Déployer des conteneurs {product-name} en utilisant Docker natif ou UCP/Swarm

Notez que le déploiement Docker natif sur Mirantis Kubernetes Engine utilisant Swarm NE prend PAS en charge le déploiement de services avec des conteneurs en mode privilégié, ou avec des capacités seccomp ajoutées. Pour déployer dans cet environnement, vous devez utiliser Docker Compose ou Run pour déployer les conteneurs {product-name}. Vous pouvez utiliser le déploiement d'hôte distant (docker-compose -H HOST) pour faciliter cette tâche.

Voici les fichiers de configuration docker compose d'exemple. Notez que l'utilisation de Docker natif ne prend pas en charge le déploiement de l'enforcer sur le même nœud que le contrôleur, nécessitant l'utilisation du conteneur Allinone si les fonctions de contrôleur et d'enforcer sont souhaitées sur un nœud.

NOTE: La variable d'environnement NV_PLATFORM_INFO=platform=Docker est utilisée pour notifier {product-name} que la plateforme est Docker/Swarm, même s'il peut y avoir des conteneurs Kubernetes inutilisés détectés par {product-name} sur un déploiement Docker EE. Aussi, pour pouvoir les voir dans l'activité réseau -> Vue -> Afficher le système, ajoutez la variable d'environnement pour l'enforcer NV_SYSTEM_GROUPS.

=== Déployer Allinone pour une haute disponibilité

Pour la HA dans des environnements de production Docker natif ou EE, déployez le conteneur Allinone sur les trois premiers hôtes de production. Chaque Allinone doit pointer vers les adresses IP de tous les hôtes Allinone. Par exemple, trois conteneurs Allinone sont le minimum pour la HA, et le CLUSTER_JOIN_ADDR doit lister les trois adresses IP séparées par des virgules. Des Allinone supplémentaires peuvent être déployés en nombres impairs, par exemple 5, 7. Déployez l'enforcer sur les hôtes restants dans le cluster, dans n'importe quel ordre.

=== Déployer Allinone en utilisant docker-compose (mode privilégié)

Voici un exemple de fichier docker-compose pour déployer le conteneur allinone sur le premier nœud. Parce que le conteneur allinone a un module d'application à l'intérieur, les conteneurs d'application sur le même nœud peuvent être sécurisés. Les déploiements greenfield et brownfield sont pris en charge.

[,yaml]
----
allinone:
    pid: host
    image: neuvector/allinone:<version>
    container_name: allinone
    privileged: true
    environment:
        - CLUSTER_JOIN_ADDR=node_ip
        - NV_PLATFORM_INFO=platform=Docker
    ports:
        - 18300:18300
        - 18301:18301
        - 18400:18400
        - 18401:18401
        - 18301:18301/udp
        - 8443:8443
    volumes:
        - /lib/modules:/lib/modules:ro
        - /var/neuvector:/var/neuvector
        - /var/run/docker.sock:/var/run/docker.sock:ro
        - /proc:/host/proc:ro
        - /sys/fs/cgroup:/host/cgroup:ro
----

La variable d'environnement la plus importante est le *CLUSTER_JOIN_ADDR*. C'est l'adresse IP à laquelle d'autres modules d'application se connectent. Normalement, elle doit être définie sur l'adresse IP du nœud où le conteneur all-in-one est en cours d'exécution.

Les ports 18300 et 18301 sont les ports par défaut pour la communication de cluster. Ils doivent être identiques pour tous les contrôleurs et modules d'application dans le cluster. Veuillez vous référer à la section _"Détails de Docker-compose"_ pour savoir comment changer les ports par défaut.

[NOTE]
====
Pour exposer l'API REST dans l'Allinone, ajoutez la carte de port pour 10443, par exemple - 10443:10443.
====

=== Ajoutez un conteneur d'application en utilisant docker-compose (mode privilégié)

Ceci est un exemple de fichier docker-compose pour rejoindre un module d'application dans le cluster. Les déploiements greenfield et brownfield sont pris en charge.

[,yaml]
----
enforcer:
    pid: host
    image: neuvector/enforcer:<version>
    container_name: enforcer
    privileged: true
    environment:
        - CLUSTER_JOIN_ADDR=controller_node_ip
        - NV_PLATFORM_INFO=platform=Docker
    ports:
        - 18301:18301
        - 18401:18401
        - 18301:18301/udp
    volumes:
        - /lib/modules:/lib/modules:ro
        - /var/run/docker.sock:/var/run/docker.sock:ro
        - /proc:/host/proc:ro
        - /sys/fs/cgroup/:/host/cgroup/:ro
----

La variable d'environnement la plus importante est *CLUSTER_JOIN_ADDR*. Pour les modules d'application, remplacez `+<controller_node_ip>+` par l'adresse IP du nœud du contrôleur. Typiquement, *CLUSTER_JOIN_ADDR* dans le fichier docker-compose du contrôleur/all-in-one et le fichier docker-compose du module d'application ont la même valeur.

=== Déployez le conteneur Scanner {product-name}

À partir de {product-name} 4.0+, un conteneur de scanner séparé doit être déployé pour effectuer une analyse de vulnérabilité. Important : Utilisez toujours le tag :latest lors du tirage et de l'exécution de l'image du scanner pour garantir que la dernière base de données CVE est déployée.

Exemple de docker run pour déployer le scanner sur le même hôte que le contrôleur.

[,shell]
----
docker run -td --name scanner -e CLUSTER_JOIN_ADDR=controller_node_ip -p 18402:18402 -v /var/run/docker.sock:/var/run/docker.sock:ro neuvector/scanner:latest
----

Et exemple docker-compose

[,yaml]
----
Scanner:
   image: neuvector/scanner:latest
   container_name: scanner
   environment:
     - CLUSTER_JOIN_ADDR=controller_node_ip
   ports:
     - 18402:18402
   volumes:
     - /var/run/docker.sock:/var/run/docker.sock:ro
----

Pour déployer le scanner sur un hôte différent de celui du contrôleur, ajoutez la variable d'environnement CLUSTER_ADVERTISED_ADDR afin que le contrôleur puisse atteindre le scanner.

[,shell]
----
docker run -td --name scanner -e CLUSTER_JOIN_ADDR=controller_node_ip -e CLUSTER_ADVERTISED_ADDR=scanner_host_ip -p 18402:18402 -v /var/run/docker.sock:/var/run/docker.sock:ro neuvector/scanner:latest
----

Pour déployer plusieurs scanners sur le même hôte que le contrôleur, supprimez le mappage de port et la variable d'environnement CLUSTER_ADVERTISED_ADDR.

[,shell]
----
docker run -itd --name s1  -e CLUSTER_JOIN_ADDR=controller_node_ip neuvector/scanner:latest
----

Où s1 est le scanner 1 (utilisez s2, s3, etc. pour chaque scanner supplémentaire).

Pour déployer un scanner autonome (sans contrôleur/allinone), veuillez consulter la section xref:scanners.adoc[Scanners parallèles et autonomes].

Pour mettre à jour le Scanner afin d'obtenir les dernières mises à jour de la base de données CVE de {product-name}, créez un job cron pour arrêter et redémarrer le scanner, en tirant la dernière version. Voir xref:docker.adoc#_docker_native_updates[cette section] pour plus de détails.

=== Déploiement sans utiliser le mode privilégié

Pour certaines configurations de plateforme, il est possible de déployer les conteneurs {product-name} sans qu'ils aient besoin de s'exécuter en mode privilégié. La configuration doit prendre en charge la possibilité d'ajouter des capacités et de définir le profil apparmor. Notez que Docker DataCenter/UCP et Swarm ne prennent actuellement pas en charge cela, mais il est toujours possible de déployer {product-name} manuellement en utilisant Compose ou Run.

=== Déployer allinone (PAS de mode privilégié) avec docker-compose

[,yaml]
----
allinone:
    pid: host
    image: neuvector/allinone:<version>
    container_name: neuvector.allinone
    cap_add:
        - SYS_ADMIN
        - NET_ADMIN
        - SYS_PTRACE
        - IPC_LOCK
    security_opt:
        - apparmor=unconfined
        - seccomp=unconfined
        - label=disable
    environment:
        - CLUSTER_JOIN_ADDR=[AllInOne Node IP Address]
        - NV_PLATFORM_INFO=platform=Docker
    ports:
        - 18300:18300
        - 18301:18301
        - 18400:18400
        - 18401:18401
        - 18301:18301/udp
        - 8443:8443
    volumes:
        - /lib/modules:/lib/modules:ro
        - /var/run/docker.sock:/var/run/docker.sock:ro
        - /proc:/host/proc:ro
        - /sys/fs/cgroup:/host/cgroup:ro
        - /var/neuvector:/var/neuvector
----

=== Déployer l'enforcer (PAS de mode privilégié) avec docker-compose

[,yaml]
----
enforcer:
    pid: host
    image: neuvector/enforcer:<version>
    container_name: neuvector.enforcer
    cap_add:
        - SYS_ADMIN
        - NET_ADMIN
        - SYS_PTRACE
        - IPC_LOCK
    security_opt:
        - apparmor=unconfined
        - seccomp=unconfined
        - label=disable
    environment:
        - CLUSTER_JOIN_ADDR=[AllInOne Node IP Address]
        - NV_PLATFORM_INFO=platform=Docker
    ports:
        - 18301:18301
        - 18401:18401
        - 18301:18301/udp
    volumes:
        - /lib/modules:/lib/modules:ro
        - /var/run/docker.sock:/var/run/docker.sock:ro
        - /proc:/host/proc:ro
        - /sys/fs/cgroup/:/host/cgroup/:ro
----

=== Déployer allinone (mode privilégié) avec docker run

Vous pouvez utiliser docker run au lieu de compose pour déployer. Voici des exemples.

[,shell]
----
docker run -d --name allinone \
--pid=host \
--privileged \
    -e CLUSTER_JOIN_ADDR=[AllInOne Node IP Address] \
    -e NV_PLATFORM_INFO=platform=Docker \
    -p 18300:18300 \
    -p 18301:18301 \
    -p 18400:18400 \
    -p 18401:18401 \
    -p 18301:18301/udp \
    -p 8443:8443 \
    -v /lib/modules:/lib/modules:ro \
    -v /var/neuvector:/var/neuvector \
    -v /var/run/docker.sock:/var/run/docker.sock:ro \
    -v /sys/fs/cgroup:/host/cgroup:ro \
    -v /proc:/host/proc:ro \
neuvector/allinone:<version>
----

=== Déployer l'enforcer (mode privilégié) avec docker run

[,shell]
----
docker run -d --name enforcer \
--pid=host \
--privileged \
    -e CLUSTER_JOIN_ADDR=[AllInOne Node IP Address] \
    -e NV_PLATFORM_INFO=platform=Docker \
    -p 18301:18301 \
    -p 18401:18401 \
    -p 18301:18301/udp \
    -v /lib/modules:/lib/modules:ro \
    -v /var/run/docker.sock:/var/run/docker.sock:ro \
    -v /sys/fs/cgroup:/host/cgroup:ro \
    -v /proc:/host/proc:ro \
neuvector/enforcer:<version>
----

=== Déployer allinone (PAS de mode privilégié) avec docker run

Vous pouvez utiliser docker run au lieu de compose pour déployer. Voici des exemples.

[,shell]
----
docker run -d --name allinone \
--pid=host \
--cap-add=SYS_ADMIN \
--cap-add=NET_ADMIN \
--cap-add=SYS_PTRACE \
--cap-add=IPC_LOCK \
--security-opt label=disable \
--security-opt apparmor=unconfined \
--security-opt seccomp=unconfined \
    -e CLUSTER_JOIN_ADDR=[AllInOne Node IP Address] \
    -e NV_PLATFORM_INFO=platform=Docker \
    -p 18300:18300 \
    -p 18301:18301 \
    -p 18400:18400 \
    -p 18401:18401 \
    -p 18301:18301/udp \
    -p 8443:8443 \
    -v /lib/modules:/lib/modules:ro \
    -v /var/neuvector:/var/neuvector \
    -v /var/run/docker.sock:/var/run/docker.sock:ro \
    -v /sys/fs/cgroup:/host/cgroup:ro \
    -v /proc:/host/proc:ro \
neuvector/allinone:<version>
----

=== Déployer l'enforcer (PAS de mode privilégié) avec docker run

[,shell]
----
docker run -d --name enforcer \
--pid=host \
--cap-add=SYS_ADMIN \
--cap-add=NET_ADMIN \
--cap-add=SYS_PTRACE \
--cap-add=IPC_LOCK \
--security-opt label=disable \
--security-opt apparmor=unconfined \
--security-opt seccomp=unconfined \
    -e CLUSTER_JOIN_ADDR=[AllInOne Node IP Address]  \
    -e NV_PLATFORM_INFO=platform=Docker \
    -p 18301:18301 \
    -p 18401:18401 \
    -p 18301:18301/udp \
    -v /lib/modules:/lib/modules:ro \
    -v /var/run/docker.sock:/var/run/docker.sock:ro \
    -v /sys/fs/cgroup:/host/cgroup:ro \
    -v /proc:/host/proc:ro \
neuvector/enforcer:<version>
----

== Déployer des composants {product-name} séparés sur différents hôtes

Si vous prévoyez de dédier un hôte docker à un Contrôleur et/ou un Gestionnaire (sans Enforcer), ces conteneurs peuvent être déployés individuellement au lieu de l'Allinone. Notez que docker ne prend pas en charge le déploiement de l'enforcer sur le même nœud que le contrôleur en tant que composants séparés, nécessitant l'utilisation du conteneur Allinone si les fonctions de contrôleur et d'enforcer sont souhaitées sur un nœud.

Fichier compose du Contrôleur (remplacez [IP du contrôleur] par l'IP du premier nœud contrôleur)

[,yaml]
----
controller:
    image: neuvector/controller:<version>
    container_name: controller
    pid: host
    privileged: true
    environment:
      - CLUSTER_JOIN_ADDR=[controller IP]
      - NV_PLATFORM_INFO=platform=Docker
    ports:
        - 18300:18300
        - 18301:18301
        - 18400:18400
        - 18401:18401
        - 18301:18301/udp
        - 10443:10443
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /proc:/host/proc:ro
      - /sys/fs/cgroup:/host/cgroup:ro
      - /var/neuvector:/var/neuvector
----

Docker run peut également être utilisé, par exemple

[,shell]
----
docker run -itd --privileged --name neuvector.controller -e CLUSTER_JOIN_ADDR=controller_ip -p 18301:18301 -p 18301:18301/udp -p 18300:18300 -p 18400:18400 -p 10443:10443 -v /var/neuvector:/var/neuvector -v /var/run/docker.sock:/var/run/docker.sock:ro -v /proc:/host/proc:ro -v /sys/fs/cgroup/:/host/cgroup/:ro neuvector/controller:<version>
----

Fichier compose du Gestionnaire (remplacez [IP du contrôleur] par l'IP du nœud contrôleur auquel se connecter). Le service HRM de Docker UCP utilise le port par défaut 8443 qui entre en conflit avec le port console {product-name}. Si vous utilisez le port HRM par défaut, changez alors le mappage de port {product-name} dans l'exemple ci-dessous vers un autre port, par exemple 9443:8443 pour le conteneur gestionnaire comme indiqué ci-dessous.

[,yaml]
----
manager:
    image: neuvector/manager:<version>
    container_name: nvmanager
    environment:
      - CTRL_SERVER_IP=[controller IP]
    ports:
      - 9443:8443
----

Le fichier compose pour l'Enforcer :

[,yaml]
----
enforcer:
    image: neuvector/enforcer:<version>
    pid: host
    container_name: enforcer
    privileged: true
    environment:
        - CLUSTER_JOIN_ADDR=controller_node_ip
        - NV_PLATFORM_INFO=platform=Docker
    ports:
        - 18301:18301
        - 18401:18401
        - 18301:18301/udp
    volumes:
        - /lib/modules:/lib/modules:ro
        - /var/run/docker.sock:/var/run/docker.sock:ro
        - /proc:/host/proc:ro
        - /sys/fs/cgroup/:/host/cgroup/:ro
----

== Surveillance et redémarrage de {product-name}

Puisque les conteneurs {product-name} ne sont pas déployés en tant que service UCP/Swarm, ils ne sont pas automatiquement démarrés/redémarrés sur les nœuds. Vous devez configurer des alertes via votre système SIEM pour les événements SYSLOG {product-name} ou via DataCenter pour détecter si un conteneur {product-name} ne fonctionne pas.

== Déploiement sans mode privilégié

En général, vous devrez remplacer le paramètre privilégié par :

[,yaml]
----
    cap_add:
        - SYS_ADMIN
        - NET_ADMIN
        - SYS_PTRACE
        - IPC_LOCK
    security_opt:
        - apparmor=unconfined
        - seccomp=unconfined
        - label=disable
----

La syntaxe ci-dessus est pour Docker EE v17.06.0+. Les versions antérieures à cela utilisent : au lieu de =, par exemple apparmor:unconfined.

== Mises à jour Docker Native

[CAUTION]
====
Utilisez toujours le tag `+:latest+` lors du tirage et de l'exécution de l'image du scanner pour garantir que la dernière base de données CVE est déployée.
====

[,shell]
----
docker stop scanner
docker rm <scanner id>
docker pull neuvector/scanner:latest
<docker run command from below>
----

[NOTE]
====
`+docker rm -f <scanner id>+` peut également être utilisé pour forcer l'arrêt et la suppression du scanner en cours d'exécution.

Pour docker-compose

[,shell]
----
docker-compose -f file.yaml down
docker-compose -f file.yaml pull        // pre-pull the image before starting the scanner
docker-compose -f file.yaml up -d
----

Exemple de docker run

[,shell]
----
docker run -td --name scanner -e CLUSTER_JOIN_ADDR=controller_node_ip -e CLUSTER_ADVERTISED_ADDR=node_ip -e SCANNER_DOCKER_URL=tcp://192.168.1.10:2376 -p 18402:18402 -v /var/run/docker.sock:/var/run/docker.sock:ro neuvector/scanner:latest
----

Et exemple docker-compose

[,yaml]
----
Scanner:
   image: neuvector/scanner:latest
   container_name: scanner
   environment:
     - SCANNER_DOCKER_URL=tcp://192.168.1.10:2376
     - CLUSTER_JOIN_ADDR=controller_node_ip
     - CLUSTER_ADVERTISED_ADDR=node_ip
   ports:
     - 18402:18402
   volumes:
     - /var/run/docker.sock:/var/run/docker.sock:ro
----
====
