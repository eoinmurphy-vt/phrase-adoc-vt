= Configuration requise
:revdate: 2025-06-02
:page-revdate: {revdate}
:page-opendocs-origin: /01.basics/02.requirements/02.requirements.md
:page-opendocs-slug: /basics/requirements

== Configuration requise

[cols="1,1,1,1,4", options="header"]
|===
| Composant | # Nombre d'instances | vCPU recommandé | Mémoire minimale | Notes

| Contrôleur
| min. 1 +
3 pour HA (numéros impairs uniquement)
| 1
| 1GB
| Le cœur du vCPU peut être partagé

| Enforcer
| 1 par nœud/VM
| 1+
| 1GB
| Un ou plusieurs vCPU dédiés pour un débit réseau plus élevé en mode Protect

| Scanner
| min. 1 +
2+ pour HA/Performance
| 1
| 1GB
| Le cœur de l'unité centrale peut être partagé pour les charges de travail standard. +
Dédier une ou plusieurs unités centrales à la numérisation de gros volumes d'images (plus de 10 000). +
La numérisation de l'image du registre est effectuée par le scanner et gérée par le contrôleur, et l'image est extraite par le scanner et développée dans la mémoire. +
La mémoire minimale recommandée suppose que les images à numériser ne dépassent pas 0,5 Go. +
Lors de la numérisation d'images d'une taille supérieure à 1 Go, la mémoire du scanner doit être calculée en prenant la taille de l'image la plus grande et en ajoutant 0,5 Go. +
Exemple - la plus grande taille d'image = 1,3 Go, la mémoire du conteneur du scanner doit être de 1,8 Go.

| Gestionnaire
| min 1 +
2+ pour HA
| 1
| 1GB
| Le vCPU peut être partagé
|===

* Pour la configuration backup/HA, un RWX PVC de 1Gi ou plus. Voir la xref:production.adoc#_backups_and_persistent_data[section Sauvegardes et données persistantes] pour plus de détails.
* Navigateur recommandé : Chrome pour de meilleures performances

== Plates-formes prises en charge

* Distributions Linux officiellement prises en charge : SUSE Linux, Ubuntu, CentOS/Red Hat (RHEL), Debian, CoreOS, AWS Bottlerocket et Photon.
* Architectures AMD64 et Arm
* CoreOS est pris en charge (novembre 2023) pour l'analyse CVE via le tableau de correspondance RHEL fourni par RedHat. Dès qu'un flux officiel sera publié par RedHat pour CoreOS, il sera pris en charge.
* Systèmes de gestion de conteneurs compatibles avec Kubernetes et Docker officiellement pris en charge. Les plates-formes suivantes sont testées avec chaque version de {product-name}: Kubernetes 1.19-1.32, SUSE Rancher (RKE, RKE2, K3s, etc.), RedHat OpenShift 4.6-4.16 (3.x à 4.12 pris en charge avant {product-name} 5.2.x), Google GKE, Amazon EKS, Microsoft Azure AKS, IBM IKS, docker natif, docker swarm. Les plateformes Kubernetes et Docker suivantes sont prises en charge et ont été vérifiées pour fonctionner avec {product-name}: VMware Photon et Tanzu, SUSE CaaS, Oracle OKE, Mirantis Kubernetes Engine, Nutanix Kubernetes Engine, docker UCP/DataCenter, docker Cloud.
* Version d'exécution de Docker : 1.9.0 et plus ; Docker API version : 1,21, CE et EE.
* Temps d'exécution de Containerd et CRI-O (nécessite de modifier les trajectoires des volumes dans les échantillons). Voir les changements requis pour Containerd dans la section sur le déploiement de Kubernetes et CRI-O dans la section sur le déploiement d'OpenShift.
* {product-name} est compatible avec la plupart des CNI du commerce. Sont officiellement testés et pris en charge openshift ovs (subnet/multitenant), calico, flannel, cilium, antrea et les clouds publics (gke, aks, iks, eks). La prise en charge de Multus a été ajoutée dans la version 5.4.0.
* Console : Navigateur Chrome ou Firefox recommandé. IE 11 n'est pas pris en charge en raison de problèmes de performance.
* Minikube est pris en charge pour une simple évaluation initiale, mais pas pour une validation complète du concept. Voir ci-dessous les changements nécessaires pour que le yaml d'Allinone fonctionne sur Minikube.

AWS Bottlerocket Note : Doit changer le chemin du socket containerd spécifique à Bottleneck. Veuillez consulter la section sur le déploiement de Kubernetes pour plus de détails.

== Non pris en charge

* GKE Autopilot.
* AWS ECS n'est plus pris en charge. (NOTE : Aucune fonctionnalité n'a été activement supprimée pour l'exploitation de {product-name} sur les déploiements ECS. Cependant, les tests sur ECS ne sont plus effectués par SUSE. La protection des charges de travail ECS à l'aide de {product-name} fonctionnera probablement comme prévu, mais les problèmes ne seront pas examinés).
* Docker sur Mac
* Docker sur Windows
* Rkt (conteneur linux) de CoreOS
* AppArmor sur les environnements K3S / SLES. Certaines configurations peuvent entrer en conflit avec {product-name} et provoquer des erreurs de scanner ; AppArmor doit être désactivé lors du déploiement de {product-name}.
* IPv6 n'est pas pris en charge
* VMWare Integrated Containers (VIC) sauf en mode imbriqué
* CloudFoundry
* Console : IE 11 n'est pas pris en charge en raison de problèmes de performance.
* Conteneur imbriqué dans un conteneur outils utilisés pour des tests simples. Par exemple, le déploiement d'un cluster Kubernetes à l'aide de 'kind' https://kind.sigs.k8s.io/docs/user/configuration/.

[NOTE]
====
PKS est testé sur le terrain et nécessite l'activation de conteneurs privilégiés sur le plan/carreau, et la modification du chemin d'accès yaml comme suit pour Allinone, Controller, Enforcer :

[,yaml]
----
            hostPath:
            path: /var/vcap/sys/run/docker/docker.sock
----
====

[NOTE]
====
{product-name} fonctionne sur des machines virtuelles basées sur linux sur Mac/Windows en utilisant Vagrant, VirtualBox, VMware ou d'autres environnements virtualisés.
====


== Minikube

Veuillez apporter les modifications suivantes au fichier Allinone deployment yaml.

[,yaml]
----
apiVersion: apps/v1 <<-- required for k8s 1.19
kind: DaemonSet
metadata:
 name: neuvector-allinone-pod
 namespace: neuvector
spec:
 selector: <-- Added
 matchLabels: <-- Added
 app: neuvector-allinone-pod <-- Added
 minReadySeconds: 60
...
 nodeSelector: <-- DELETE THIS LINE
 nvallinone: "true" <-- DELETE THIS LINE
apiVersion: apps/v1 <<-- required for k8s 1.19
kind: DaemonSet
metadata:
 name: neuvector-enforcer-pod
 namespace: neuvector
spec:
 selector: <-- Added
 matchLabels: <-- Added
 app: neuvector-enforcer-pod <-- Added
----

== Performances et mise à l'échelle

Comme toujours, la planification des performances pour les conteneurs {product-name} dépend de plusieurs facteurs, notamment

* (contrôleur et scanner) Nombre et taille des images du registre à numériser (par le scanner) initialement
* (Enforcer) Mode Services (Discover, Monitor, Protect), où le mode Protect fonctionne comme un pare-feu en ligne.
* (Enforcer) Type de connexions réseau pour les charges de travail en mode Protect

En mode surveillance (filtrage du réseau similaire à un miroir/une prise), il n'y a pas d'impact sur les performances et l'Enforcer traite le trafic à la vitesse de la ligne, en générant des alertes si nécessaire. En mode protection (pare-feu en ligne), l'Enforcer a besoin de CPU et de mémoire pour filtrer les connexions à l'aide d'une inspection approfondie des paquets et les mettre en attente afin de déterminer si elles doivent être bloquées ou supprimées. En règle générale, avec 1 Go de mémoire et un processeur partagé, l'Enforcer devrait être en mesure de gérer la plupart des environnements en mode protection.

Pour les environnements sensibles au débit ou à la latence, une mémoire supplémentaire et/ou un cœur de processeur dédié peuvent être alloués au conteneur {product-name} Enforcer.

Pour l'optimisation des performances du contrôleur et du scanner pour l'analyse du registre, voir la configuration requise ci-dessus.

Pour des conseils supplémentaires sur les performances et le dimensionnement, voir la xref:production.adoc#_best_practices_tips_qa_for_deploying_and_managing_suse_security[section Embarquement/Bonnes pratiques.]

=== Débit

Comme le montre le graphique ci-dessous, les tests de référence du débit de base ont montré un débit maximal de 1,3 Gbps PAR NODE sur une petite instance de cloud public avec 4 cœurs de CPU. Par exemple, une grappe de 10 nœuds pourrait alors gérer un débit maximal de 13 Gbps pour l'ensemble de la grappe pour les services en mode protégé.

image:throughput.png[Débit]

Ce débit devrait augmenter au fur et à mesure qu'une unité centrale dédiée est affectée à l'Enforcer, ou que la vitesse de l'unité centrale change, et/ou que de la mémoire supplémentaire est allouée. Là encore, la mise à l'échelle dépendra du type de trafic réseau/application des charges de travail.

=== Temps de latence

La latence est une autre mesure de performance qui dépend du type de connexions réseau. Comme pour le débit, la latence n'est pas affectée en mode surveillance, mais seulement pour les services en mode protection (pare-feu en ligne). Les petits paquets ou les services simples/rapides généreront un pourcentage de latence plus élevé par {product-name}, tandis que les paquets plus importants ou les services nécessitant un traitement complexe afficheront un pourcentage plus faible de latence ajoutée par l'applicateur de {product-name}.

Le tableau ci-dessous montre la latence moyenne de 2 à 10 % mesurée à l'aide de l'outil de benchmarking Redis. Le benchmark Redis utilise des paquets assez petits, de sorte que la latence avec des paquets plus grands devrait être plus faible.

|===
| Test | Moniteur | Protéger | Temps de latence

| PING_INLINE
| 34,904
| 31,603
| 9.46%

| SET
| 38,618
| 36,157
| 6.37%

| GET
| 36,055
| 35,184
| 2.42%

| LPUSH
| 39,853
| 35,994
| 9.68%

| RPUSH
| 37,685
| 36,010
| 4.45%

| LPUSH (LRANGE Benchmark)
| 37,399
| 35,220
| 5.83%

| LRANGE_100
| 25,539
| 23,906
| 6.39%

| LRANGE_300
| 13,082
| 12,277
| 6.15%
|===

Le benchmark ci-dessus montre le TPS moyen du mode Protect par rapport au mode Monitor, ainsi que la latence ajoutée pour le mode Protect pour plusieurs tests du benchmark. Le principal moyen de réduire la latence réelle (microsecondes) en mode protection consiste à utiliser un système doté d'un processeur plus rapide. Vous trouverez plus de détails sur cet outil de benchmarking Redis open source à l'adresse suivante https://redis.io/topics/benchmarks.

=== Ajout de contraintes de mise à l'échelle pour les environnements à forte charge de travail

Lors de l'installation de NeuVector, si votre système d'exploitation hôte a une grande quantité de charges de travail, les pods NeuVector Enforcer peuvent échouer à démarrer lorsqu'ils essaient d'ouvrir le grand volume de fichiers en raison de la surveillance de l'hôte des pods. Cela peut également entraîner des défaillances du serveur RKE2 en raison du grand nombre de fichiers ouverts.

En guise de solution de contournement pour les environnements à forte charge de travail, vous devez créer un fichier tel que `+example-fs-max.conf+` à l'emplacement `+/etc/sysctl.d/+` et ajouter des contraintes de mise à l'échelle avec la configuration suivante :

[,shell]
----
fs.inotify.max_user_instances=8192
fs.inotify.max_user_watches=524288
fs.filemax=5000
----

Assurez-vous ensuite que la configuration est appliquée avec un redémarrage via la commande suivante :

[,shell]
----
systemctl restart systemd-sysctl
----