= Systemanforderungen
:revdate: 2025-06-02
:page-revdate: {revdate}
:page-opendocs-origin: /01.basics/02.requirements/02.requirements.md
:page-opendocs-slug: /grundlagen/voraussetzungen

== Systemanforderungen

[cols="1,1,1,1,4", options="header"]
|===
| Komponente | # Anzahl der Instanzen | Empfohlene vCPU | Minimaler Speicher | Anmerkungen

| Controller
| min. 1 +
3 für HA (nur ungerade Zahlen)
| 1
| 1GB
| vCPU-Kern kann gemeinsam genutzt werden

| Vollstrecker
| 1 pro Knoten/VM
| 1+
| 1GB
| Eine oder mehrere dedizierte vCPUs für höheren Netzwerkdurchsatz im Protect-Modus

| Scanner
| min. 1 +
2+ für HA/Leistung
| 1
| 1GB
| Der CPU-Kern kann für Standardarbeitslasten gemeinsam genutzt werden. +
Dedizieren Sie 1 oder mehrere CPUs für das Scannen großer Mengen (10k+) von Bildern. +
Das Scannen des Registerbildes wird vom Scanner durchgeführt und vom Steuergerät verwaltet, und das Bild wird vom Scanner gezogen und im Speicher erweitert. +
Die Empfehlung für den Mindestspeicher setzt voraus, dass die zu scannenden Bilder nicht größer als 0,5 GB sind. +
Beim Scannen von Bildern, die größer als 1 GB sind, sollte der Scanner-Speicher anhand der größten Bildgröße zuzüglich 0,5 GB berechnet werden. +
Beispiel - größte Bildgröße = 1,3 GB, der Speicher des Scanner-Containers sollte 1,8 GB betragen

| Manager
| min 1 +
2+ für HA
| 1
| 1GB
| vCPU kann gemeinsam genutzt werden
|===

* Für Konfigurationssicherung/HA eine RWX-PVC von 1Gi oder mehr. Weitere Informationen finden Sie im xref:production.adoc#_backups_and_persistent_data[Abschnitt Sicherungen und dauerhafte Daten].
* Empfohlener Browser: Chrome für bessere Leistung

== Unterstützte Plattformen

* Offiziell unterstützte Linux-Distributionen: SUSE Linux, Ubuntu, CentOS/Red Hat (RHEL), Debian, CoreOS, AWS Bottlerocket und Photon.
* AMD64- und Arm-Architekturen
* CoreOS wird (November 2023) für CVE-Scans durch die von RedHat bereitgestellte RHEL-Zuordnungstabelle unterstützt. Sobald ein offizieller Feed von RedHat für CoreOS veröffentlicht wird, wird dieser unterstützt.
* Offiziell unterstützte Kubernetes- und Docker-konforme Container-Management-Systeme. Die folgenden Plattformen werden mit jeder Version von {product-name} getestet: Kubernetes 1.19-1.32, SUSE Rancher (RKE, RKE2, K3s usw.), RedHat OpenShift 4.6-4.16 (3.x bis 4.12 vor {product-name} 5.2.x unterstützt), Google GKE, Amazon EKS, Microsoft Azure AKS, IBM IKS, native Docker, Docker Swarm. Die folgenden Kubernetes- und Docker-kompatiblen Plattformen werden unterstützt und sind für die Zusammenarbeit mit {product-name} geprüft worden: VMware Photon und Tanzu, SUSE CaaS, Oracle OKE, Mirantis Kubernetes Engine, Nutanix Kubernetes Engine, Docker UCP/DataCenter, Docker Cloud.
* Version der Docker-Laufzeit: 1.9.0 und höher; Docker API Version: 1.21, CE und EE.
* Containerd- und CRI-O-Laufzeiten (erfordert Änderungen an den Volumenpfaden in den Probenahmeplänen). Siehe erforderliche Änderungen für Containerd im Abschnitt über die Bereitstellung von Kubernetes und CRI-O im Abschnitt über die Bereitstellung von OpenShift.
* {product-name} ist mit den meisten kommerziell unterstützten CNI's kompatibel. Offiziell getestet und unterstützt werden openshift ovs (subnet/multitenant), calico, flannel, cilium, antrea und public clouds (gke, aks, iks, eks). Unterstützung für Multus wurde in v5.4.0 hinzugefügt.
* Konsole: Chrome- oder Firefox-Browser empfohlen. IE 11 wird aufgrund von Leistungsproblemen nicht unterstützt.
* Minikube wird für eine einfache erste Bewertung unterstützt, aber nicht für einen vollständigen Konzeptnachweis. Siehe unten für Änderungen, die erforderlich sind, damit die Allinone yaml auf Minikube läuft.

AWS Bottlerocket Note: Muss den Pfad des containerd-Sockets speziell für Bottleneck ändern. Weitere Informationen finden Sie im Abschnitt Kubernetes-Bereitstellung.

== Nicht unterstützt

* GKE Autopilot.
* AWS ECS wird nicht mehr unterstützt. (ANMERKUNG: Es wurden keine Funktionen für den Betrieb von {product-name} auf ECS-Installationen aktiv entfernt. Die Tests auf ECS werden jedoch nicht mehr von SUSE durchgeführt. Während der Schutz von ECS-Workloads mit {product-name} wahrscheinlich wie erwartet funktioniert, werden Probleme nicht untersucht).
* Docker auf dem Mac
* Docker unter Windows
* Rkt (Container-Linux) von CoreOS
* AppArmor auf K3S / SLES-Umgebungen. Bestimmte Konfigurationen können mit {product-name} in Konflikt geraten und Scannerfehler verursachen; AppArmor sollte bei der Bereitstellung von {product-name} deaktiviert werden.
* IPv6 wird nicht unterstützt
* VMWare Integrated Containers (VIC) außer im verschachtelten Modus
* CloudFoundry
* Konsole: IE 11 wird aufgrund von Leistungsproblemen nicht unterstützt.
* Verschachtelter Container-Host in einem Container-Tool, das für einfache Tests verwendet wird. Beispiel: Bereitstellung eines Kubernetes-Clusters mit 'kind' https://kind.sigs.k8s.io/docs/user/configuration/.

[NOTE]
====
PKS ist feldgetestet und erfordert die Aktivierung von privilegierten Containern für den Plan/die Kachel und die Änderung des yaml hostPath wie folgt für Allinone, Controller, Enforcer:

[,yaml]
----
            hostPath:
            path: /var/vcap/sys/run/docker/docker.sock
----
====

[NOTE]
====
{product-name} unterstützt die Ausführung auf linuxbasierten VMs auf Mac/Windows unter Verwendung von Vagrant, VirtualBox, VMware oder anderen virtualisierten Umgebungen.
====


== Minikube

Bitte nehmen Sie die folgenden Änderungen an der Allinone deployment yaml vor.

[,yaml]
----
apiVersion: apps/v1 <<-- required for k8s 1.19
kind: DaemonSet
metadata:
 name: neuvector-allinone-pod
 namespace: neuvector
spec:
 selector: <-- Added
 matchLabels: <-- Added
 app: neuvector-allinone-pod <-- Added
 minReadySeconds: 60
...
 nodeSelector: <-- DELETE THIS LINE
 nvallinone: "true" <-- DELETE THIS LINE
apiVersion: apps/v1 <<-- required for k8s 1.19
kind: DaemonSet
metadata:
 name: neuvector-enforcer-pod
 namespace: neuvector
spec:
 selector: <-- Added
 matchLabels: <-- Added
 app: neuvector-enforcer-pod <-- Added
----

== Leistung und Skalierung

Wie immer hängt die Leistungsplanung für {product-name} Container von mehreren Faktoren ab, u. a:

* (Controller & Scanner) Anzahl und Größe der zu scannenden Bilder in der Registratur (durch den Scanner) ursprünglich
* (Enforcer) Dienste-Modus (Discover, Monitor, Protect), wobei der Protect-Modus als Inline-Firewall läuft
* (Enforcer) Typ der Netzwerkverbindungen für Workloads im Schutzmodus

Im Monitormodus (Netzwerkfilterung ähnlich einem Mirror/Tap) gibt es keine Leistungseinbußen, und der Enforcer verarbeitet den Datenverkehr mit Leitungsgeschwindigkeit und generiert bei Bedarf Warnmeldungen. Im Protect-Modus (Inline-Firewall) benötigt der Enforcer CPU und Speicher, um Verbindungen mit Deep Packet Inspection zu filtern und zu prüfen, ob sie blockiert/gekappt werden sollten. Im Allgemeinen sollte der Enforcer mit 1 GB Arbeitsspeicher und einer gemeinsam genutzten CPU in der Lage sein, die meisten Umgebungen im Schutzmodus zu bewältigen.

Für durchsatz- oder latenzempfindliche Umgebungen kann dem {product-name} Enforcer-Container zusätzlicher Speicher und/oder ein dedizierter CPU-Kern zugewiesen werden.

Informationen zur Leistungsoptimierung des Controllers und des Scanners für das Scannen der Registrierung finden Sie oben unter Systemanforderungen.

Weitere Ratschläge zu Leistung und Dimensionierung finden Sie im xref:production.adoc#_best_practices_tips_qa_for_deploying_and_managing_suse_security[Abschnitt Onboarding/Best Practices].

=== Durchsatz

Wie das Diagramm unten zeigt, ergaben die grundlegenden Durchsatz-Benchmark-Tests einen maximalen Durchsatz von 1,3 Gbit/s PRO NODE auf einer kleinen öffentlichen Cloud-Instanz mit 4 CPU-Kernen. Ein 10-Knoten-Cluster wäre dann beispielsweise in der Lage, einen maximalen Durchsatz von 13 Gbit/s für den gesamten Cluster für Dienste im Protect-Modus zu bewältigen.

image:throughput.png[Durchsatz]

Dieser Durchsatz wird voraussichtlich ansteigen, wenn dem Enforcer eine dedizierte CPU zugewiesen wird oder sich die CPU-Geschwindigkeit ändert und/oder zusätzlicher Speicher zugewiesen wird. Auch hier hängt die Skalierung von der Art des Netzwerk-/Anwendungsverkehrs der Workloads ab.

=== Latenzzeit

Die Latenzzeit ist eine weitere Leistungskennzahl, die von der Art der Netzverbindungen abhängt. Ähnlich wie der Durchsatz wird die Latenz im Monitor-Modus nicht beeinflusst, nur bei Diensten im Protect-Modus (Inline-Firewall). Kleine Pakete oder einfache/schnelle Dienste erzeugen eine höhere prozentuale Latenz durch {product-name}, während größere Pakete oder Dienste, die eine komplexe Verarbeitung erfordern, einen geringeren prozentualen Anteil an zusätzlicher Latenz durch den {product-name} enforcer aufweisen.

Die folgende Tabelle zeigt die durchschnittliche Latenz von 2-10 %, die mit dem Redis-Benchmark-Tool gemessen wurde. Der Redis-Benchmark verwendet relativ kleine Pakete, so dass die Latenzzeit bei größeren Paketen voraussichtlich geringer ist.

|===
| Test | Monitor | Schützen Sie | Latenzzeit

| PING_INLINE
| 34,904
| 31,603
| 9.46%

| SET
| 38,618
| 36,157
| 6.37%

| GET
| 36,055
| 35,184
| 2.42%

| LPUSH
| 39,853
| 35,994
| 9.68%

| RPUSH
| 37,685
| 36,010
| 4.45%

| LPUSH (LRANGE Benchmark)
| 37,399
| 35,220
| 5.83%

| LRANGE_100
| 25,539
| 23,906
| 6.39%

| LRANGE_300
| 13,082
| 12,277
| 6.15%
|===

Der obige Benchmark zeigt die durchschnittliche TPS des Protect-Modus im Vergleich zum Monitor-Modus und die für den Protect-Modus hinzugefügte Latenz für mehrere Tests im Benchmark. Die tatsächliche Latenzzeit (Mikrosekunden) im Protect-Modus lässt sich vor allem durch den Einsatz eines Systems mit einer schnelleren CPU verringern. Weitere Einzelheiten zu diesem quelloffenen Redis-Benchmark-Tool finden Sie unter https://redis.io/topics/benchmarks.

=== Hinzufügen von Skalierungsbeschränkungen für große Workload-Umgebungen

Wenn Ihr Host-Betriebssystem während der NeuVector-Installation eine große Menge an Arbeitslasten aufweist, kann es vorkommen, dass die NeuVector Enforcer-Pods beim Versuch, die große Menge an Dateien zu öffnen, aufgrund der Host-Überwachung der Pods nicht hochfahren. Dies kann auch zu Ausfällen des RKE2-Servers führen, da eine große Anzahl von Dateien geöffnet ist.

Als Workaround für große Workload-Umgebungen müssen Sie eine Datei wie `example-fs-max.conf` am Speicherort `/etc/sysctl.d/` erstellen und Skalierungsbeschränkungen mit der folgenden Konfiguration hinzufügen:

[,shell]
----
fs.inotify.max_user_instances=8192
fs.inotify.max_user_watches=524288
fs.filemax=5000
----

Stellen Sie anschließend sicher, dass die Konfiguration durch einen Neustart mit dem folgenden Befehl übernommen wird:

[,shell]
----
systemctl restart systemd-sysctl
----