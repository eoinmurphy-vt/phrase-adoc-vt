= RedHat OpenShift
:revdate: 2025-06-05
:page-revdate: {revdate}
:page-opendocs-origin: /02.deploying/04.openshift/04.openshift.md
:page-opendocs-slug: /Bereitstellung/Openshift

== Bereitstellung separater {product-name} Komponenten mit RedHat OpenShift

{product-name} ist sowohl mit den Standard-SDN-Plug-ins von ovs als auch mit anderen wie Flanell, Gewebe oder Kattun kompatibel. In den folgenden Beispielen wird davon ausgegangen, dass ein Standard-Ovs-Plug-in verwendet wird. Dies setzt auch voraus, dass eine lokale Docker-Registry verwendet wird (siehe Anweisungen am Ende zur Erstellung des Geheimnisses für den dynamischen Abruf von neuvector oder Docker Hub).

{product-name} unterstützt den Helm-basierten Einsatz mit einer https://github.com/neuvector/neuvector-helm[Helm-Karte] unter https://github.com/neuvector/neuvector-helm.. Der {product-name} Operator kann ebenfalls für den Einsatz verwendet werden und basiert auf der Helm-Karte. Um die neuesten {product-name} Container-Versionen mit einem Operator einzusetzen, verwenden Sie bitte entweder den Red Hat Certified Operator von Operator Hub oder den Community-Operator, wie im xref:operators.adoc[Abschnitt Operator] beschrieben.

Zur manuellen Bereitstellung ziehen Sie zunächst die entsprechenden {product-name} Container aus der {product-name} Registry in Ihre lokale Registry. Hinweis: Das Scanner-Image sollte regelmäßig für CVE-Datenbank-Updates von {product-name} gezogen werden.

=== {product-name} Bilder auf Docker Hub

Die Images befinden sich in der {product-name} Docker Hub Registry. Verwenden Sie das entsprechende Versions-Tag für Manager, Controller und Enforcer und belassen Sie die Version für Scanner und Updater auf "latest". Zum Beispiel:

* neuvector/manager:5.4.3
* neuvector/controller:5.4.3
* neuvector/enforcer:5.4.3
* neuvector/scanner:latest
* neuvector/updater:latest

Bitte stellen Sie sicher, dass Sie die Bildreferenzen in den entsprechenden yaml-Dateien aktualisieren.

Wenn Sie mit dem aktuellen {product-name} Helm-Diagramm (v1.8.9+) bereitstellen, sollten Sie die folgenden Änderungen an values.yml vornehmen:

* Aktualisieren Sie die Registry auf docker.io
* Aktualisieren Sie die Image-Namen/Tags auf die aktuelle Version im Docker-Hub, wie oben gezeigt
* Lassen Sie das Feld imagePullSecrets leer

== Bereitstellung auf OpenShift

[,shell]
----
docker login docker.io
docker pull docker.io/neuvector/manager:<version>
docker pull docker.io/neuvector/controller:<version>
docker pull docker.io/neuvector/enforcer:<version>
docker pull docker.io/neuvector/scanner
docker pull docker.io/neuvector/updater
docker logout docker.io
----

Die unten stehende Beispieldatei wird einen Manager, 3 Controller und 2 Scanner-Pods bereitstellen. Er setzt einen Enforcer auf jedem Knoten als Daemonset ein, auch auf dem Masterknoten (falls planbar). Siehe den unteren Abschnitt zur Angabe von dedizierten Manager- oder Controllerknoten mit Hilfe von Knotenbeschriftungen. Anmerkung: Es wird nicht empfohlen, mehr als einen Manager hinter einem Load Balancer einzusetzen (zu skalieren), da es zu Problemen mit dem Sitzungsstatus kommen kann. Wenn Sie planen, einen PersistentVolume-Anspruch zu verwenden, um die Sicherung der {product-name} Konfigurationsdateien zu speichern, lesen Sie bitte den allgemeinen Abschnitt Sicherung/Persistente Daten in der Übersicht über die xref:production.adoc#_backups_and_persistent_data[Produktionsbereitstellung].

Legen Sie dann die Route fest und erlauben Sie privilegierte {product-name} Container anhand der folgenden Anweisungen. OpenShift erlaubt standardmäßig keine privilegierten Container. Außerdem plant OpenShift standardmäßig keine Pods auf dem Master-Knoten. Siehe die Anweisungen am Ende, um dies zu aktivieren/deaktivieren.

[NOTE]
====
Einzelheiten zur Integration mit OpenShift Role Based Access Controls (RBACs) finden Sie im Abschnitt Enterprise Integration.
====

. Anmeldung als normaler Benutzer
+
--
[,shell]
----
oc login -u <user_name>
----
--
. Erstellen Sie ein neues Projekt.
+
--
[NOTE]
====
Wenn das --node-selector-Argument beim Erstellen eines Projekts verwendet wird, schränkt dies die Pod-Platzierung, z. B. für den {product-name} enforcer, auf bestimmte Knoten ein.
====

[,shell]
----
oc new-project neuvector
----
--
. Pushen Sie {product-name} Bilder in die OpenShift Docker-Registry.
+
--
[NOTE]
====
Für OpenShift 4.6+, ändern Sie docker-registry.default.svc in den folgenden Befehlen in image-registry.openshift-image-registry.svc
====

[,shell]
----
docker login -u <user_name> -p `oc whoami -t` docker-registry.default.svc:5000
docker tag docker.io/neuvector/enforcer:<version> docker-registry.default.svc:5000/neuvector/enforcer:<version>
docker tag docker.io/neuvector/controller:<version> docker-registry.default.svc:5000/neuvector/controller:<version>
docker tag docker.io/neuvector/manager:<version> docker-registry.default.svc:5000/neuvector/manager:<version>
docker tag docker.io/neuvector/scanner docker-registry.default.svc:5000/neuvector/scanner
docker tag docker.io/neuvector/updater docker-registry.default.svc:5000/neuvector/updater
docker push docker-registry.default.svc:5000/neuvector/enforcer:<version>
docker push docker-registry.default.svc:5000/neuvector/controller:<version>
docker push docker-registry.default.svc:5000/neuvector/manager:<version>
docker push docker-registry.default.svc:5000/neuvector/scanner
docker push docker-registry.default.svc:5000/neuvector/updater
docker logout docker-registry.default.svc:5000
----

[NOTE]
====
Bitte lesen Sie den Abschnitt Aktualisieren der CVE-Datenbank weiter unten für Empfehlungen, wie Sie das neueste Scanner-Image in Ihrer Registrierung auf dem neuesten Stand halten.
====
--
. Anmeldung als system:admin-Konto
+
--
[,shell]
----
oc login -u system:admin
----
--
. Erstellen von Dienstkonten und Erteilen von Zugriff auf die privilegierte SCC
+
--
[,shell]
----
oc create sa controller -n neuvector
oc create sa enforcer -n neuvector
oc create sa basic -n neuvector
oc create sa updater -n neuvector
oc create sa scanner -n neuvector
oc create sa registry-adapter -n neuvector
oc create sa cert-upgrader -n neuvector
oc -n neuvector adm policy add-scc-to-user privileged -z enforcer
----

Die folgenden Informationen werden zu den Privilegierten SCC-Benutzern hinzugefügt:

[,yaml]
----
- system:serviceaccount:neuvector:enforcer
----

Fügen Sie einen neuen neuvector-scc-controller scc für das Controller-Servicekonto in Openshift hinzu, indem Sie eine Datei mit erstellen:

[,yaml]
----
allowHostDirVolumePlugin: false
allowHostIPC: false
allowHostNetwork: false
allowHostPID: false
allowHostPorts: false
allowPrivilegeEscalation: false
allowPrivilegedContainer: false
allowedCapabilities: null
apiVersion: security.openshift.io/v1
defaultAddCapabilities: null
fsGroup:
  type: RunAsAny
groups: []
kind: SecurityContextConstraints
metadata:
  name: neuvector-scc-controller
priority: null
readOnlyRootFilesystem: false
requiredDropCapabilities:
- ALL
runAsUser:
  type: RunAsAny
seLinuxContext:
  type: RunAsAny
supplementalGroups:
  type: RunAsAny
users: []
volumes:
- configMap
- downwardAPI
- emptyDir
- persistentVolumeClaim
- azureFile
- projected
- secret
----

Dann gelten

[,shell]
----
oc apply -f (filename)
----

Führen Sie dann den folgenden Befehl aus, um das Controller-Dienstkonto an neuvector-scc-controller scc zu binden

[,shell]
----
oc -n neuvector adm policy add-scc-to-user neuvector-scc-controller -z controller
----

In OpenShift 4.6+ verwenden Sie die folgende Methode zur Überprüfung:

[,shell]
----
oc get rolebinding system:openshift:scc:privileged -n neuvector -o wide
----

[,shell]
----
NAME                              ROLE                                          AGE     USERS   GROUPS   SERVICEACCOUNTS
system:openshift:scc:privileged   ClusterRole/system:openshift:scc:privileged   9m22s                    neuvector/enforcer
----

Führen Sie diesen Befehl aus, um den Dienst {product-name} für Controller zu überprüfen:

[,shell]
----
oc get rolebinding system:openshift:scc:neuvector-scc-controller -n neuvector -o wide
----

Die Ausgabe sieht dann so aus

[,shell]
----
NAME                                            ROLE                                                        AGE     USERS   GROUPS   SERVICEACCOUNTS
System:openshift:scc:neuvector-scc-controller   ClusterRole/system:openshift:scc:neuvector-scc-controller   9m22s                    neuvector/controller
----
--
. Erstellen Sie die benutzerdefinierten Ressourcen (CRD) für {product-name} Sicherheitsregeln. Für OpenShift 4.6+ (Kubernetes 1.19+):
+
--
[,shell]
----
oc apply -f https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.4.0/crd-k8s-1.19.yaml
oc apply -f https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.4.0/waf-crd-k8s-1.19.yaml
oc apply -f https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.4.0/dlp-crd-k8s-1.19.yaml
oc apply -f https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.4.0/com-crd-k8s-1.19.yaml
oc apply -f https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.4.0/vul-crd-k8s-1.19.yaml
oc apply -f https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.4.0/admission-crd-k8s-1.19.yaml
oc apply -f https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.4.0/5.4.3_group-definition-k8s.yaml
----
--
. Fügen Sie eine Leseberechtigung für den Zugriff auf die Kubernetes-API und OpenShift RBACs hinzu. 
+
[IMPORTANT]
====
Die Standardimplementierung von {product-name} 5.2+ verwendet Dienstkonten mit den geringsten Rechten anstelle der Standardkonten. Siehe unten, wenn Sie ein Upgrade auf 5.2+ von einer Version vor 5.2 durchführen.
====
+
--
[CAUTION]
========
Wenn Sie auf 5.3.0+ aktualisieren, führen Sie die folgenden Befehle auf der Grundlage Ihrer aktuellen Version aus:

[tabs]
======
Version 5.2.0::
+
====
[,shell]
----
oc delete clusterrole neuvector-binding-nvsecurityrules neuvector-binding-nvadmissioncontrolsecurityrules neuvector-binding-nvdlpsecurityrules neuvector-binding-nvwafsecurityrules
----
==== 

Versionen vor 5.2.0::
+
====
[,shell]
----
oc delete clusterrolebinding neuvector-binding-app neuvector-binding-rbac neuvector-binding-admission neuvector-binding-customresourcedefinition neuvector-binding-nvsecurityrules neuvector-binding-view neuvector-binding-nvwafsecurityrules neuvector-binding-nvadmissioncontrolsecurityrules neuvector-binding-nvdlpsecurityrules neuvector-binding-co oc delete rolebinding neuvector-admin -n neuvector
----
====
======
========

[,shell]
----
oc create clusterrole neuvector-binding-app --verb=get,list,watch,update --resource=nodes,pods,services,namespaces
oc create clusterrole neuvector-binding-rbac --verb=get,list,watch --resource=rolebindings.rbac.authorization.k8s.io,roles.rbac.authorization.k8s.io,clusterrolebindings.rbac.authorization.k8s.io,clusterroles.rbac.authorization.k8s.io,imagestreams.image.openshift.io
oc adm policy add-cluster-role-to-user neuvector-binding-app system:serviceaccount:neuvector:controller
oc adm policy add-cluster-role-to-user neuvector-binding-rbac system:serviceaccount:neuvector:controller
oc create clusterrole neuvector-binding-admission --verb=get,list,watch,create,update,delete --resource=validatingwebhookconfigurations,mutatingwebhookconfigurations
oc adm policy add-cluster-role-to-user neuvector-binding-admission system:serviceaccount:neuvector:controller
oc create clusterrole neuvector-binding-customresourcedefinition --verb=watch,create,get,update --resource=customresourcedefinitions
oc adm policy add-cluster-role-to-user neuvector-binding-customresourcedefinition system:serviceaccount:neuvector:controller
oc create clusterrole neuvector-binding-nvsecurityrules --verb=get,list,delete --resource=nvsecurityrules,nvclustersecurityrules
oc create clusterrole neuvector-binding-nvadmissioncontrolsecurityrules --verb=get,list,delete --resource=nvadmissioncontrolsecurityrules
oc create clusterrole neuvector-binding-nvdlpsecurityrules --verb=get,list,delete --resource=nvdlpsecurityrules
oc create clusterrole neuvector-binding-nvwafsecurityrules --verb=get,list,delete --resource=nvwafsecurityrules
oc adm policy add-cluster-role-to-user neuvector-binding-nvsecurityrules system:serviceaccount:neuvector:controller
oc adm policy add-cluster-role-to-user view system:serviceaccount:neuvector:controller --rolebinding-name=neuvector-binding-view
oc adm policy add-cluster-role-to-user neuvector-binding-nvwafsecurityrules system:serviceaccount:neuvector:controller
oc adm policy add-cluster-role-to-user neuvector-binding-nvadmissioncontrolsecurityrules system:serviceaccount:neuvector:controller
oc adm policy add-cluster-role-to-user neuvector-binding-nvdlpsecurityrules system:serviceaccount:neuvector:controller
oc create role neuvector-binding-scanner --verb=get,patch,update,watch --resource=deployments -n neuvector
oc adm policy add-role-to-user neuvector-binding-scanner system:serviceaccount:neuvector:updater system:serviceaccount:neuvector:controller -n neuvector --role-namespace neuvector
oc create clusterrole neuvector-binding-co --verb=get,list --resource=clusteroperators
oc adm policy add-cluster-role-to-user neuvector-binding-co system:serviceaccount:neuvector:enforcer system:serviceaccount:neuvector:controller
oc create role neuvector-binding-secret --verb=get,list,watch --resource=secrets -n neuvector
oc adm policy add-role-to-user neuvector-binding-secret system:serviceaccount:neuvector:controller system:serviceaccount:neuvector:enforcer system:serviceaccount:neuvector:scanner system:serviceaccount:neuvector:registry-adapter -n neuvector --role-namespace neuvector
oc create clusterrole neuvector-binding-nvcomplianceprofiles --verb=get,list,delete --resource=nvcomplianceprofiles
oc create clusterrolebinding neuvector-binding-nvcomplianceprofiles --clusterrole=neuvector-binding-nvcomplianceprofiles --serviceaccount=neuvector:controller
oc create clusterrole neuvector-binding-nvvulnerabilityprofiles --verb=get,list,delete --resource=nvvulnerabilityprofiles
oc create clusterrolebinding neuvector-binding-nvvulnerabilityprofiles --clusterrole=neuvector-binding-nvvulnerabilityprofiles --serviceaccount=neuvector:controller
oc apply -f https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.4.0/neuvector-roles-k8s.yaml
oc create role neuvector-binding-lease --verb=create,get,update --resource=leases -n neuvector
oc adm policy add-role-to-user neuvector-binding-cert-upgrader system:serviceaccount:neuvector:cert-upgrader -n neuvector --role-namespace neuvector
oc adm policy add-role-to-user neuvector-binding-job-creation system:serviceaccount:neuvector:cert-upgrader -n neuvector --role-namespace neuvector
oc adm policy add-role-to-user neuvector-binding-lease system:serviceaccount:neuvector:controller system:serviceaccount:neuvector:cert-upgrader -n neuvector --role-namespace neuvector
oc create clusterrole neuvector-binding-nvgroupdefinitions --verb=get,list,delete --resource=nvgroupdefinitions
oc create clusterrolebinding neuvector-binding-nvgroupdefinitions --clusterrole=neuvector-binding-nvgroupdefinitions --serviceaccount=neuvector:controller
----
--
. Führen Sie den folgenden Befehl aus, um zu überprüfen, ob die Dienstkonten neuvector/controller, neuvector/enforcer und neuvector/updater erfolgreich hinzugefügt wurden.
+
--
[,shell]
----
oc get ClusterRoleBinding neuvector-binding-app neuvector-binding-rbac neuvector-binding-admission neuvector-binding-customresourcedefinition neuvector-binding-nvsecurityrules neuvector-binding-view neuvector-binding-nvwafsecurityrules neuvector-binding-nvadmissioncontrolsecurityrules neuvector-binding-nvdlpsecurityrules neuvector-binding-co -o wide
----

Beispielhafte Ausgabe:

[,shell]
----
NAME                                                ROLE                                                            AGE   USERS   GROUPS   SERVICEACCOUNTS
neuvector-binding-app                               ClusterRole/neuvector-binding-app                               56d                    neuvector/controller
neuvector-binding-rbac                              ClusterRole/neuvector-binding-rbac                              34d                    neuvector/controller
neuvector-binding-admission                         ClusterRole/neuvector-binding-admission                         72d                    neuvector/controller
neuvector-binding-customresourcedefinition          ClusterRole/neuvector-binding-customresourcedefinition          72d                    neuvector/controller
neuvector-binding-nvsecurityrules                   ClusterRole/neuvector-binding-nvsecurityrules                   72d                    neuvector/controller
neuvector-binding-view                              ClusterRole/view                                                72d                    neuvector/controller
neuvector-binding-nvwafsecurityrules                ClusterRole/neuvector-binding-nvwafsecurityrules                72d                    neuvector/controller
neuvector-binding-nvadmissioncontrolsecurityrules   ClusterRole/neuvector-binding-nvadmissioncontrolsecurityrules   72d                    neuvector/controller
neuvector-binding-nvdlpsecurityrules                ClusterRole/neuvector-binding-nvdlpsecurityrules                72d                    neuvector/controller
neuvector-binding-co                                ClusterRole/neuvector-binding-co                                72d                    neuvector/enforcer, neuvector/controller
----

Und dieser Befehl:

[,shell]
----
oc get RoleBinding neuvector-binding-scanner neuvector-binding-cert-upgrader neuvector-binding-job-creation neuvector-binding-lease neuvector-binding-secret -n neuvector -o wide
----

Beispielhafte Ausgabe:

[,shell]
----
NAME                              ROLE                                   AGE   USERS   GROUPS   SERVICEACCOUNTS
neuvector-binding-scanner         Role/neuvector-binding-scanner         56m                    neuvector/controller, neuvector/updater
neuvector-binding-cert-upgrader   Role/neuvector-binding-cert-upgrader   56m                    neuvector/cert-upgrader
neuvector-binding-job-creation    Role/neuvector-binding-job-creation    56m                    neuvector/controller
neuvector-binding-lease           Role/neuvector-binding-lease           56m                    neuvector/controller, neuvector/cert-upgrader
neuvector-binding-secret          Role/neuvector-binding-secret          56m                    neuvector/controller, neuvector/enforcer, neuvector/scanner, neuvector/registry-adapter
----
--
. *(Optional*) Erstellen Sie die Federation Master und/oder Remote Multi-Cluster Management Services. Wenn Sie die Multi-Cluster-Verwaltungsfunktionen in {product-name} verwenden möchten, muss auf einem Cluster der Federation Master-Dienst und auf jedem Remote-Cluster der Federation Worker-Dienst installiert sein. Um flexibel zu sein, können Sie auf jedem Cluster sowohl Master- als auch Worker-Dienste einrichten, so dass jeder Cluster als Master oder Remote fungieren kann.
+
--
Föderierte Verwaltungsdienste

[,yaml]
----
apiVersion: v1
kind: Service
metadata:
  name: neuvector-service-controller-fed-master
  namespace: neuvector
spec:
  ports:
  - port: 11443
    name: fed
    protocol: TCP
  type: NodePort
  selector:
    app: neuvector-controller-pod

---

apiVersion: v1
kind: Service
metadata:
  name: neuvector-service-controller-fed-worker
  namespace: neuvector
spec:
  ports:
  - port: 10443
    name: fed
    protocol: TCP
  type: NodePort
  selector:
    app: neuvector-controller-pod
----

Erstellen Sie dann den/die entsprechenden Dienst(e):

[,shell]
----
oc create -f nv_master_worker.yaml
----
--
. Erstellen Sie die neuvector-Dienste und -Pods auf der Grundlage der unten stehenden Beispiel-Yamls. 
+
[IMPORTANT] 
====
Ersetzen Sie die <version> Tags für die Manager-, Controller- und Enforcer-Bildreferenzen in der yaml-Datei. Nehmen Sie auch alle anderen Änderungen vor, die für Ihre Einsatzumgebung erforderlich sind.
====
+
--
[,shell]
----
oc create -f <compose file>
----
--

Das war's! Sie sollten in der Lage sein, sich mit der Konsole {product-name} zu verbinden und sich mit admin:admin anzumelden, z. B. `https://<public-ip>:8443`

Um zu sehen, wie man auf die Konsole des neuvector-webui-Dienstes zugreift:

[,shell]
----
oc get services -n neuvector
----

Wenn Sie Ihren eigenen Namespace erstellt haben, anstatt "`neuvector`" zu verwenden, ersetzen Sie alle Instanzen von "`namespace: neuvector`" und andere Namespace-Referenzen durch Ihren Namespace in den folgenden Beispiel-Yaml-Dateien.

*OpenShift 4.6+ mit CRI-O-Laufzeit*

Der Name Ihrer OpenShift-Standardregistrierung hat sich möglicherweise von docker-registry in openshift-image-registry geändert. Möglicherweise müssen Sie die Image-Registrierung für den Manager, Controller und Enforcer in der Beispiel-Yaml-Datei ändern.

[NOTE]
====
Der Typ NodePort wird für die fed-master und fed-worker Dienste anstelle von LoadBalancer verwendet. Möglicherweise müssen Sie diese für Ihren Einsatz anpassen.
====

Wenn Sie die CRI-O-Laufzeit verwenden, lesen Sie dieses https://raw.githubusercontent.com/neuvector/manifests/main/kubernetes/5.4.0/neuvector-crio-oc.yaml[CRI-O-Beispiel].

*Master-Knoten Taints und Toleranzen*

Alle Taint-Informationen müssen übereinstimmen, um Enforcer auf Knoten zu planen. So prüfen Sie die Taint-Informationen eines Knotens (z. B. Master):

[,shell]
----
$ oc get node taintnodename -o yaml
----

Beispielhafte Ausgabe:

[,yaml]
----
spec:
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
  # there may be an extra info for taint as below
  - effect: NoSchedule
    key: mykey
    value: myvalue
----

Wenn es zusätzliche Färbungen wie oben gibt, fügen Sie diese in den Abschnitt "Beispiel-Yaml-Toleranzen" ein:

[,yaml]
----
spec:
  template:
    spec:
      tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
        # if there is an extra info for taints as above, please add it here. This is required to match all the taint info defined on the taint node. Otherwise, the Enforcer won't deploy on the taint node
        - effect: NoSchedule
          key: mykey
          value: myvalue
----

== Verwendung von Knotenetiketten für Manager- und Controller-Knoten

Um zu kontrollieren, auf welchen Knoten der Manager und der Controller eingesetzt werden, kennzeichnen Sie jeden Knoten. Ersetzen Sie `<nodename>` durch den entsprechenden Knotennamen.

[,shell]
----
oc label nodes <nodename> nvcontroller=true
----

Fügen Sie dann einen nodeSelector in die yaml-Datei für die Bereitstellungsabschnitte Manager und Controller ein. Zum Beispiel:

[,yaml]
----
          - mountPath: /host/cgroup
              name: cgroup-vol
              readOnly: true
      nodeSelector:
        nvcontroller: "true"
      restartPolicy: Always
----

Um zu verhindern, dass der Enforcer auf einem Controller-Knoten eingesetzt wird, wenn es sich um einen dedizierten Management-Knoten handelt (ohne zu überwachende Anwendungscontainer), fügen Sie dem Abschnitt Enforcer yaml eine nodeAffinity hinzu. Zum Beispiel:

[,yaml]
----
app: neuvector-enforcer-pod
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                - key: nvcontroller
                  operator: NotIn
                  values: ["true"]
      imagePullSecrets:
----

== Aktualisieren der CVE-Datenbank in OpenShift-Bereitstellungen

Das neueste Scanner-Image enthält immer das aktuellste CVE-Datenbank-Update von {product-name}. Aus diesem Grund wird ein Versions-Tag beim Abrufen des Bildes nicht empfohlen. Die Aktualisierung der CVE-Datenbank erfordert jedoch ein regelmäßiges Abrufen des neuesten Scanner-Images, damit der Updater-Cron-Job den/die Scanner neu bereitstellen kann.  Die obigen Beispiele gehen davon aus, dass {product-name} -Images gezogen, getaggt und in eine lokale OpenShift-Registry gepusht werden. Die Bereitstellung erfolgt dann über diese Registrierung statt direkt über neuvector (oder die alte {product-name} -Registrierung auf Docker Hub).

Um die CVE-Datenbank regelmäßig zu aktualisieren, empfehlen wir die Erstellung eines Skripts/Cron-Jobs, der das neueste Scanner-Image von {product-name} abruft und die Markierungs- und Push-Schritte in der lokalen Registrierung durchführt. Auf diese Weise wird sichergestellt, dass die CVE-Datenbank regelmäßig aktualisiert wird und Images und Container auf neue Schwachstellen gescannt werden.

== Laufende Aktualisierungen

Orchestrierungswerkzeuge wie Kubernetes, RedHat OpenShift und Rancher unterstützen rollierende Updates mit konfigurierbaren Richtlinien. Sie können diese Funktion nutzen, um die {product-name} Container zu aktualisieren. Am wichtigsten ist es, sicherzustellen, dass mindestens ein Allinone/Controller läuft, damit Richtlinien, Protokolle und Verbindungsdaten nicht verloren gehen. Achten Sie darauf, dass zwischen den Aktualisierungen der Container mindestens 30 Sekunden vergehen, damit ein neuer Leader gewählt und die Daten zwischen den Controllern synchronisiert werden können.

Bevor Sie mit den Rolling Updates beginnen, ziehen Sie bitte die {product-name} Container und markieren Sie sie auf die gleiche Weise wie am Anfang dieser Seite. Sie können die neueste Version auch ohne Versionsnummer abrufen, aber um die rollierende Aktualisierung auszulösen, müssen Sie das Bild mit einer Versionsnummer versehen.

Zum Beispiel für den Controller (zuletzt):

[,shell]
----
docker pull neuvector/controller
----

Dann zu tag/push, wenn die letzte Version 2.0.1 ist, wie in Schritt 3 oben auf dieser Seite:

[,shell]
----
docker login -u <user_name> -p `oc whoami -t` docker-registry.default.svc:5000
docker tag neuvector/controller docker-registry.default.svc:5000/neuvector/controller:2.0.1
docker push docker-registry.default.svc:5000/neuvector/controller:2.0.1
----

Sie können nun Ihre yaml-Datei mit diesen neuen Versionen und '`apply`' aktualisieren oder den Befehl '`oc set image ...`' verwenden, um das Rolling Update auszulösen. In den Kubernetes-Beispielen für rollende Aktualisierungen in diesem Abschnitt über die Produktion erfahren Sie, wie Sie rollende Aktualisierungen der {product-name} -Container starten und überwachen können.

In den bereitgestellten Beispielen für die Bereitstellung ist die Rolling-Update-Richtlinie bereits konfiguriert. Wenn Sie die Aktualisierung über das {product-name} Helm-Diagramm vornehmen, ziehen Sie bitte das neueste Diagramm heran, um neue Funktionen wie die Zugangskontrolle ordnungsgemäß zu konfigurieren, und löschen Sie die alte Clusterrolle und die Clusterrollenbindung für {product-name}.

== Aktivieren der REST-API

Um die Rest-API zu aktivieren, muss der Port 10443 wie folgt konfiguriert werden:

[,yaml]
----
apiVersion: v1
kind: Service
metadata:
  name: neuvector-service-controller
  namespace: neuvector
spec:
  ports:
    - port: 10443
      name: controller
      protocol: TCP
  type: NodePort
  selector:
    app: neuvector-controller-pod
----

== Aktivieren/Deaktivieren der Zeitplanung auf dem Master-Knoten

Mit den folgenden Befehlen können Sie die Zeitplanung auf dem Master-Knoten aktivieren/deaktivieren.

[,shell]
----
oc adm manage-node nodename --schedulable
----

[,shell]
----
oc adm manage-node nodename --schedulable=false
----

== OpenShift-Bereitstellung im nicht-privilegierten Modus

Die folgenden Anweisungen können verwendet werden, um {product-name} ohne Verwendung von Containern im privilegierten Modus einzusetzen. Der Controller befindet sich bereits im nicht privilegierten Modus, und der Enforcer-Einsatz sollte geändert werden, wie in den folgenden Auszügen gezeigt wird.

Vollstrecker:

[,yaml]
----
spec:
  template:
    metadata:
      annotations:
        container.apparmor.security.beta.kubernetes.io/neuvector-enforcer-pod: unconfined
      # this line below is required to be added if k8s version is pre-v1.19
      # container.seccomp.security.alpha.kubernetes.io/neuvector-enforcer-pod: unconfined
    spec:
      containers:
          securityContext:
            # openshift
            seLinuxOptions:
              type: unconfined_t
            # the following two lines are required for k8s v1.19+. pls comment out both lines if version is pre-1.19. Otherwise, a validating data error message will show
            seccompProfile:
              type: Unconfined
            capabilities:
              add:
              - SYS_ADMIN
              - NET_ADMIN
              - SYS_PTRACE
              - IPC_LOCK
              - NET_RAW
              - SYS_CHROOT
              - MKNOD
              - AUDIT_WRITE
              - SETFCAP
----

Das folgende Beispiel ist eine vollständige Einsatzreferenz unter Verwendung der cri-o-Laufzeit. Für andere Laufzeiten nehmen Sie bitte die entsprechenden Änderungen an den Volumes/Volume-Mounts für die crio.sock vor.

.Klicken Sie hier für Details
[%collapsible]
====
[,yaml]
----
apiVersion: v1
kind: Service
metadata:
  name: neuvector-svc-crd-webhook
  namespace: neuvector
spec:
  ports:
  - port: 443
    targetPort: 30443
    protocol: TCP
    name: crd-webhook
  type: ClusterIP
  selector:
    app: neuvector-controller-pod

---

apiVersion: v1
kind: Service
metadata:
  name: neuvector-svc-admission-webhook
  namespace: neuvector
spec:
  ports:
  - port: 443
    targetPort: 20443
    protocol: TCP
    name: admission-webhook
  type: ClusterIP
  selector:
    app: neuvector-controller-pod

---

apiVersion: v1
kind: Service
metadata:
  name: neuvector-service-webui
  namespace: neuvector
spec:
  ports:
    - port: 8443
      name: manager
      protocol: TCP
  type: ClusterIP
  selector:
    app: neuvector-manager-pod

---

apiVersion: v1
kind: Service
metadata:
  name: neuvector-svc-controller
  namespace: neuvector
spec:
  ports:
  - port: 18300
    protocol: "TCP"
    name: "cluster-tcp-18300"
  - port: 18301
    protocol: "TCP"
    name: "cluster-tcp-18301"
  - port: 18301
    protocol: "UDP"
    name: "cluster-udp-18301"
  clusterIP: None
  selector:
    app: neuvector-controller-pod

---

apiVersion: route.openshift.io/v1
kind: Route
metadata:
  name: neuvector-route-webui
  namespace: neuvector
spec:
  to:
    kind: Service
    name: neuvector-service-webui
  port:
    targetPort: manager
  tls:
    termination: passthrough

---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: neuvector-manager-pod
  namespace: neuvector
spec:
  selector:
    matchLabels:
      app: neuvector-manager-pod
  replicas: 1
  template:
    metadata:
      labels:
        app: neuvector-manager-pod
    spec:
      serviceAccountName: basic
      serviceAccount: basic
      containers:
        - name: neuvector-manager-pod
          image: image-registry.openshift-image-registry.svc:5000/neuvector/manager:<version>
          env:
            - name: CTRL_SERVER_IP
              value: neuvector-svc-controller.neuvector
      restartPolicy: Always

---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: neuvector-controller-pod
  namespace: neuvector
spec:
  selector:
    matchLabels:
      app: neuvector-controller-pod
  minReadySeconds: 60
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  replicas: 3
  template:
    metadata:
      labels:
        app: neuvector-controller-pod
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - neuvector-controller-pod
              topologyKey: "kubernetes.io/hostname"
      serviceAccountName: controller
      serviceAccount: controller
      containers:
        - name: neuvector-controller-pod
          image: image-registry.openshift-image-registry.svc:5000/neuvector/controller:<version>
          securityContext:
            runAsUser: 0
          readinessProbe:
            exec:
              command:
              - cat
              - /tmp/ready
            initialDelaySeconds: 5
            periodSeconds: 5
          env:
            - name: CLUSTER_JOIN_ADDR
              value: neuvector-svc-controller.neuvector
            - name: CLUSTER_ADVERTISED_ADDR
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: CLUSTER_BIND_ADDR
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            # - name: CTRL_PERSIST_CONFIG
            #   value: "1"
          volumeMounts:
            # - mountPath: /var/neuvector
            #   name: nv-share
            #   readOnly: false
            - mountPath: /etc/config
              name: config-volume
              readOnly: true
      terminationGracePeriodSeconds: 300
      restartPolicy: Always
      volumes:
        # - name: nv-share
        #   persistentVolumeClaim:
        #     claimName: neuvector-data
        - name: config-volume
          projected:
            sources:
              - configMap:
                  name: neuvector-init
                  optional: true
              - secret:
                  name: neuvector-init
                  optional: true
              - secret:
                  name: neuvector-secret
                  optional: true

---

apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: neuvector-enforcer-pod
  namespace: neuvector
spec:
  selector:
    matchLabels:
      app: neuvector-enforcer-pod
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: neuvector-enforcer-pod
      annotations:
        container.apparmor.security.beta.kubernetes.io/neuvector-enforcer-pod: unconfined
      # Add the following for pre-v1.19
      # container.seccomp.security.alpha.kubernetes.io/neuvector-enforcer-pod: unconfined
    spec:
      tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/master
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
      hostPID: true
      serviceAccountName: enforcer
      serviceAccount: enforcer
      containers:
        - name: neuvector-enforcer-pod
          image: image-registry.openshift-image-registry.svc:5000/neuvector/enforcer:<version>
          securityContext:
            # openshift
            seLinuxOptions:
              type: unconfined_t
            # the following two lines are required for k8s v1.19+. pls comment out both lines if version is pre-1.19. Otherwise, a validating data error message will show
            seccompProfile:
              type: Unconfined
            capabilities:
              add:
              - SYS_ADMIN
              - NET_ADMIN
              - SYS_PTRACE
              - IPC_LOCK
              - NET_RAW
              - SYS_CHROOT
              - MKNOD
              - AUDIT_WRITE
              - SETFCAP
          env:
            - name: CLUSTER_JOIN_ADDR
              value: neuvector-svc-controller.neuvector
            - name: CLUSTER_ADVERTISED_ADDR
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: CLUSTER_BIND_ADDR
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
          volumeMounts:
            - mountPath: /lib/modules
              name: modules-vol
              readOnly: true
            # - mountPath: /run/runtime.sock
            #   name: runtime-sock
            #   readOnly: true
            # - mountPath: /host/proc
            #   name: proc-vol
            #   readOnly: true
            # - mountPath: /host/cgroup
            #   name: cgroup-vol
            #   readOnly: true
            - mountPath: /var/nv_debug
              name: nv-debug
              readOnly: false
      terminationGracePeriodSeconds: 1200
      restartPolicy: Always
      volumes:
        - name: modules-vol
          hostPath:
            path: /lib/modules
        # - name: runtime-sock
        #   hostPath:
        #     path: /var/run/crio/crio.sock
        # - name: proc-vol
        #   hostPath:
        #     path: /proc
        # - name: cgroup-vol
        #   hostPath:
        #     path: /sys/fs/cgroup
        - name: nv-debug
          hostPath:
            path: /var/nv_debug

---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: neuvector-scanner-pod
  namespace: neuvector
spec:
  selector:
    matchLabels:
      app: neuvector-scanner-pod
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  replicas: 2
  template:
    metadata:
      labels:
        app: neuvector-scanner-pod
    spec:
      serviceAccountName: scanner
      serviceAccount: scanner
      containers:
        - name: neuvector-scanner-pod
          image: image-registry.openshift-image-registry.svc:5000/neuvector/scanner:<version>
          imagePullPolicy: Always
          env:
            - name: CLUSTER_JOIN_ADDR
              value: neuvector-svc-controller.neuvector
      restartPolicy: Always

---

apiVersion: batch/v1
kind: CronJob
metadata:
  name: neuvector-updater-pod
  namespace: neuvector
spec:
  schedule: "0 0 * * *"
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: neuvector-updater-pod
        spec:
          serviceAccountName: updater
          serviceAccount: updater
          containers:
          - name: neuvector-updater-pod
            image: image-registry.openshift-image-registry.svc:5000/neuvector/updater:<version>
            imagePullPolicy: Always
            command:
            - /bin/sh
            - -c
            - TOKEN=`cat /var/run/secrets/kubernetes.io/serviceaccount/token`; /usr/bin/curl -kv -X PATCH -H "Authorization:Bearer $TOKEN" -H "Content-Type:application/strategic-merge-patch+json" -d '{"spec":{"template":{"metadata":{"annotations":{"kubectl.kubernetes.io/restartedAt":"'`date +%Y-%m-%dT%H:%M:%S%z`'"}}}}}' 'https://kubernetes.default/apis/apps/v1/namespaces/neuvector/deployments/neuvector-scanner-pod'
          restartPolicy: Never
----
====
